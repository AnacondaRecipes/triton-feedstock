{% set version = "2.1.0" %}

package:
  name: triton
  version: {{ version }}

source:
  git_url: https://github.com/openai/triton.git
  git_rev: e6216047b8b0aef1fe8da6ca8667a3ad0a016411
  patches:
    - patches/0003-properly-point-to-triton-includes.patch
    - patches/0004-Avoid-using-outdated-FindLLVM.patch
    - patches/0005-Unvendor-pybind-and-lit.patch
    - patches/0007-Fix-TableGen-issues.patch
    - patches/0008-Search-for-libs-in-CONDA_PREFIX-instead-of-third_par.patch
    - patches/0009-build-llvm-in-src-dir.patch
    - patches/0010-always-use-ubuntu-llvm-source.patch
    - patches/turn-off-optimizations.patch
  
build:
  number: 0
  # Currently we need this to support PyTorch's torch.compile feature on Nvidia GPUs, linux-64.
  skip: true  # [not (linux and x86_64)]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}

requirements:
  build:
    - {{ compiler('cxx') }}
    - make
    - cmake
    #- mlir
    #- llvmdev
  host:
    - cudatoolkit {{ cuda_compiler_version }}*
    - python
    - pybind11
    - pip
    #- llvm
    #- mlir
    - zlib
  run:
    - python
    - filelock
    - pytorch
    - lit
    - {{ pin_compatible('cudatoolkit', max_pin='x.x') }}

test:
  imports:
    - triton
    - triton._C.libtriton
  requires:
    - pip
    - pytest
    - scipy
  source_files:
    - python/test
  commands:
    - pip check
    # test suite essentially depends on availability of a physical GPU,
    # see https://github.com/openai/triton/issues/466;
    # so this package needs to be built and tested on a GPU builder
    - pytest -v python/test

about:
  home: https://github.com/openai/triton
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: Development repository for the Triton language and compiler
  description: |
    This is the development repository of Triton, a language and compiler for writing highly efficient custom Deep-Learning primitives.
    The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA, but also with higher flexibility than other existing DSLs.
  doc_url: https://triton-lang.org/
  dev_url: https://github.com/openai/triton

extra:
  recipe-maintainers:
    - erip
    - h-vetinari
